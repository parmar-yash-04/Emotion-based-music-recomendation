import streamlit as st
import cv2
import numpy as np
import tensorflow as tf
from PIL import Image
import plotly.express as px
import plotly.graph_objects as go
from emotion_model import EmotionDetector
from music_recommender import MusicRecommender
import base64
from io import BytesIO
import time

# Page configuration
st.set_page_config(
    page_title="üéµ Emotion-Based Music Recommender",
    page_icon="üéµ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 2rem;
    }
    
    .emotion-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    
    .music-card {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #667eea;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        color: #000000;
    }
    
    .pill {
        display: inline-block;
        padding: 6px 12px;
        margin: 6px 6px 0 0;
        border-radius: 999px;
        background: rgba(255,255,255,0.85);
        color: #111;
        border: 1px solid #e3e6ef;
        box-shadow: 0 1px 4px rgba(0,0,0,0.06);
        font-weight: 600;
    }
    
    .song-item {
        background: linear-gradient(180deg, #ffffff, #f6f7fb);
        color: #111;
        padding: 14px 18px;
        border-radius: 12px;
        margin: 8px 0;
        border: 1px solid #e6e9f2;
        box-shadow: 0 2px 8px rgba(0,0,0,0.06);
        transition: transform 0.15s ease, box-shadow 0.15s ease;
    }
    .song-item:hover { 
        transform: translateY(-2px);
        box-shadow: 0 6px 18px rgba(0,0,0,0.12);
        border-left: 4px solid #667eea;
    }
    .song-item a { color: #111; text-decoration: none; font-weight: 600; }
    .section-title { font-size: 1.6rem; font-weight: 800; margin: 16px 0 8px; }
    
    .confidence-bar {
        background: linear-gradient(90deg, #ff6b6b, #feca57, #48dbfb, #ff9ff3);
        height: 20px;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
    
    .stButton > button {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 25px;
        padding: 0.5rem 2rem;
        font-weight: bold;
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }
    
    .sidebar .sidebar-content {
        background: linear-gradient(180deg, #667eea 0%, #764ba2 100%);
    }
    
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        text-align: center;
        margin: 0.5rem 0;
        color: #000000;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'emotion_detector' not in st.session_state:
    st.session_state.emotion_detector = None
if 'music_recommender' not in st.session_state:
    st.session_state.music_recommender = MusicRecommender()
if 'last_prediction' not in st.session_state:
    st.session_state.last_prediction = None
if 'page' not in st.session_state:
    st.session_state.page = "üè† Home"

def load_emotion_model():
    """Load the emotion detection model"""
    if st.session_state.emotion_detector is None:
        with st.spinner("Loading emotion detection model..."):
            detector = EmotionDetector()
            if detector.load_model():
                st.session_state.emotion_detector = detector
                return True
            else:
                st.error("Model not found! Please train the model first.")
                return False
    return True

def process_image(image):
    """Process uploaded image for emotion detection"""
    # Convert PIL to OpenCV format
    image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

    # Convert to grayscale and enhance contrast
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    gray_eq = clahe.apply(gray)

    # Load cascades
    frontal_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    alt_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml')

    faces = ()
    # Try multiple parameter sets for robustness
    param_grid = [
        (1.1, 5, (60, 60)),
        (1.05, 5, (60, 60)),
        (1.2, 3, (40, 40)),
        (1.3, 3, (30, 30)),
    ]

    for scale, neighbors, min_size in param_grid:
        faces = frontal_cascade.detectMultiScale(gray_eq, scaleFactor=scale, minNeighbors=neighbors, minSize=min_size)
        if len(faces) == 0:
            faces = alt_cascade.detectMultiScale(gray_eq, scaleFactor=scale, minNeighbors=neighbors, minSize=min_size)
        if len(faces) > 0:
            break

    if len(faces) > 0:
        x, y, w, h = faces[0]
        face_roi = gray_eq[y:y+h, x:x+w]
        return face_roi

    # Fallback: center-crop a square from the image if no face is detected
    h_img, w_img = gray_eq.shape[:2]
    side = min(h_img, w_img)
    cx, cy = w_img // 2, h_img // 2
    half = side // 2
    x0, y0 = max(0, cx - half), max(0, cy - half)
    x1, y1 = x0 + side, y0 + side
    fallback_roi = gray_eq[y0:y1, x0:x1]
    st.info("No face detected. Using center crop as fallback for emotion detection.")
    return fallback_roi

def create_emotion_radar_chart(predictions):
    """Create a radar chart for emotion predictions"""
    emotions = list(predictions.keys())
    values = list(predictions.values())
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatterpolar(
        r=values,
        theta=emotions,
        fill='toself',
        name='Emotion Confidence',
        line_color='rgb(102, 126, 234)',
        fillcolor='rgba(102, 126, 234, 0.3)'
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 1]
            )),
        showlegend=True,
        title="Emotion Confidence Distribution",
        font=dict(size=12)
    )
    
    return fig

def main():
    # Header
    st.markdown('<h1 class="main-header">üéµ Emotion-Based Music Recommender</h1>', unsafe_allow_html=True)
    st.markdown("---")
    
    # Sidebar
    with st.sidebar:
        st.markdown("## üéØ Navigation")
        nav_options = ["üè† Home", "üì∏ Emotion Detection", "üéµ Music Recommendations", "üìä Analytics", "‚ÑπÔ∏è About"]
        current_index = nav_options.index(st.session_state.page) if st.session_state.page in nav_options else 0
        page = st.selectbox("Choose a page:", nav_options, index=current_index, key="nav_select")
        # Keep session state in sync with selection
        if page != st.session_state.page:
            st.session_state.page = page
        
        st.markdown("---")
        st.markdown("## üìà Supported Emotions")
        st.markdown("Happy ‚Ä¢ Sad ‚Ä¢ Angry ‚Ä¢ Fear ‚Ä¢ Surprise ‚Ä¢ Disgust ‚Ä¢ Neutral")
    
    # Main content based on selected page
    if page == "üè† Home":
        show_home_page()
    elif page == "üì∏ Emotion Detection":
        show_emotion_detection_page()
    elif page == "üéµ Music Recommendations":
        show_music_recommendations_page()
    elif page == "üìä Analytics":
        show_analytics_page()
    elif page == "‚ÑπÔ∏è About":
        show_about_page()

def show_home_page():
    """Display the home page"""
    # Minimal hero section
    st.markdown("""
    <div style="padding:28px;border-radius:16px;background:linear-gradient(135deg,#667eea 0%, #764ba2 100%);color:white;box-shadow:0 10px 30px rgba(0,0,0,0.15);margin-bottom:16px;">
        <h1 style="margin:0 0 8px 0;">üéµ Emotion-Based Music Recommender</h1>
        <p style="margin:0;opacity:0.95;">Instantly turn your mood into a personalized playlist.</p>
    </div>
    """, unsafe_allow_html=True)
    
    if st.button("üéØ Start Detecting Emotions", key="start_btn"):
        st.session_state.page = "üì∏ Emotion Detection"
        st.rerun()
    
    # Short Feature highlights
    st.markdown("---")
    st.markdown("## ‚ú® Feature Highlights")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("""
        <div class="metric-card">
            <h3>üéØ Accurate</h3>
            <p>Reliable emotion detection</p>
        </div>
        """, unsafe_allow_html=True)
    with col2:
        st.markdown("""
        <div class="metric-card">
            <h3>üéµ Personalized</h3>
            <p>Mood‚Äëbased music picks</p>
        </div>
        """, unsafe_allow_html=True)
    with col3:
        st.markdown("""
        <div class="metric-card">
            <h3>‚ö° Fast</h3>
            <p>Instant recommendations</p>
        </div>
        """, unsafe_allow_html=True)

def show_emotion_detection_page():
    """Display the emotion detection page"""
    st.markdown("## üì∏ Emotion Detection")
    st.markdown("Upload an image or use your camera to detect emotions!")
    
    # Load model
    if not load_emotion_model():
        return
    
    # Image input options (aligned)
    row_uploader, row_toggle = st.columns([3, 1], vertical_alignment="top")

    with row_uploader:
        uploaded_file = st.file_uploader(
            "Choose an image file",
            type=['jpg', 'jpeg', 'png'],
            help="Upload a clear image with a visible face"
        )

    with row_toggle:
        st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
        use_camera = st.checkbox("Use Camera", help="Take a photo using your device's camera")
    
    camera_input = None
    if use_camera:
        camera_input = st.camera_input("Take a picture")
    
    # Process image
    image_to_process = None
    if uploaded_file is not None:
        image_to_process = Image.open(uploaded_file)
    elif camera_input is not None:
        image_to_process = Image.open(camera_input)
    
    if image_to_process is not None:
        # Display original image (compact preview, centered)
        st.markdown("### üì∑ Your Image")
        left, mid, right = st.columns([1, 2, 1])
        with mid:
            st.image(image_to_process, caption="Uploaded Image", use_container_width=False, width=350)
        
        # Process and detect emotion
        if st.button("üîç Detect Emotion", key="detect_btn"):
            with st.spinner("Analyzing your emotion..."):
                # Process image
                processed_image = process_image(image_to_process)
                
                if processed_image is not None:
                    # Detect emotion
                    result = st.session_state.emotion_detector.predict_emotion(processed_image)
                    
                    if result:
                        st.session_state.last_prediction = result
                        
                        # Display results
                        st.markdown("### üéØ Detection Results")
                        
                        col1, col2 = st.columns([1, 2])
                        
                        with col1:
                            emotion = result['emotion']
                            confidence = result['confidence']
                            emoji = st.session_state.music_recommender.get_emotion_emoji(emotion)
                            color = st.session_state.music_recommender.get_emotion_color(emotion)
                            
                            st.markdown(f"""
                            <div class="emotion-card" style="background: {color};">
                                <h2>{emoji} {emotion.title()}</h2>
                                <h3>Confidence: {confidence:.1%}</h3>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        with col2:
                            # Minimal: show only confidence bar
                            confidence_percent = confidence * 100
                            st.markdown(f"**Confidence Level: {confidence_percent:.1f}%**")
                            st.progress(confidence)
                        
                        # Music recommendation button only
                    #     st.markdown("---")
                    #     if st.button("üéµ Get Music Recommendations", key="music_btn"):
                    #         st.session_state.page = "üéµ Music Recommendations"
                    #         # Render recommendations immediately to avoid relying on rerun timing
                    #         show_music_recommendations_page(force_emotion=emotion)
                    #         return
                    # else:
                    #     st.error("Failed to detect emotion. Please try with a different image.")

def show_music_recommendations_page(force_emotion: str | None = None):
    """Display the music recommendations page"""
    st.markdown("## üéµ Music Recommendations")
    
    if st.session_state.last_prediction is None and not force_emotion:
        st.warning("Please detect an emotion first by going to the Emotion Detection page.")
        if st.button("üîç Go to Emotion Detection"):
            st.session_state.page = "üì∏ Emotion Detection"
            st.rerun()
        return
    
    # Resolve emotion/confidence
    if force_emotion:
        emotion = (force_emotion or "").strip().lower()
        confidence = st.session_state.last_prediction['confidence'] if st.session_state.last_prediction else 1.0
    else:
        emotion = st.session_state.last_prediction['emotion']
        confidence = st.session_state.last_prediction['confidence']
    
    # Display detected emotion
    emoji = st.session_state.music_recommender.get_emotion_emoji(emotion)
    color = st.session_state.music_recommender.get_emotion_color(emotion)
    
    st.markdown(f"""
    <div class="emotion-card" style="background: {color};">
        <h2>Detected Emotion: {emoji} {emotion.title()}</h2>
        <p>Confidence: {confidence:.1%}</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Get recommendations
    recommendations = st.session_state.music_recommender.get_recommendations(emotion, 8)
    
    # Manual override if needed
    with st.expander("Manual pick (use if list is empty)"):
        manual_emotion = st.selectbox(
            "Pick emotion",
            ["happy", "sad", "angry", "fear", "surprise", "disgust", "neutral"],
            index=6
        )
        if st.button("Show playlist for selected emotion"):
            manual_rec = st.session_state.music_recommender.get_recommendations(manual_emotion, 8)
            if manual_rec:
                st.markdown("### üéº Playlist Information (Manual)")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Mood", manual_rec['mood'])
                    st.metric("Tempo", manual_rec['tempo'])
                with col2:
                    st.metric("Energy Level", manual_rec['energy'])
                    st.metric("Valence", manual_rec['valence'])
                with col3:
                    st.metric("Playlist Name", manual_rec['playlist_name'])
                st.markdown("### üéµ Recommended Songs")
                for i, song in enumerate(manual_rec['recommended_songs'], 1):
                    st.markdown(f"""
                    <div class="music-card">
                        <strong>{i}. {song}</strong>
                    </div>
                    """, unsafe_allow_html=True)
    
    if recommendations and recommendations.get('recommended_songs'):
        # Playlist info
        st.markdown("### üéº Playlist Information")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Mood", recommendations['mood'])
            st.metric("Tempo", recommendations['tempo'])
        
        with col2:
            st.metric("Energy Level", recommendations['energy'])
            st.metric("Valence", recommendations['valence'])
        
        with col3:
            st.metric("Playlist Name", recommendations['playlist_name'])
        
        # Genres as pills
        st.markdown("### üé≠ Music Genres")
        st.markdown(" ".join([f"<span class='pill'>{g}</span>" for g in recommendations['genres']]), unsafe_allow_html=True)
        
        # Recommended songs - attractive list with YouTube links
        st.markdown("### üéµ Recommended Songs")
        for i, song in enumerate(recommendations['recommended_songs'], 1):
            query = song.replace(" ", "+")
            url = f"https://www.youtube.com/results?search_query={query}"
            st.markdown(f"""
            <div class="song-item">
                {i}. <a href="{url}" target="_blank">{song}</a>
            </div>
            """, unsafe_allow_html=True)
        
        # Recommended artists
        st.markdown("### üé§ Recommended Artists")
        artist_cols = st.columns(len(recommendations['recommended_artists']))
        for i, artist in enumerate(recommendations['recommended_artists']):
            with artist_cols[i]:
                st.markdown(f"<div class='music-card'><strong>{artist}</strong></div>", unsafe_allow_html=True)
        
        # Playlist description
        st.markdown("### üìù Playlist Description")
        description = st.session_state.music_recommender.get_playlist_description(emotion)
        st.info(description)
        
        # Action buttons
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üîÑ Get New Recommendations"):
                st.rerun()
        
        with col2:
            if st.button("üìä View Analytics"):
                st.session_state.page = "üìä Analytics"
                st.rerun()
        
        with col3:
            if st.button("üì∏ Detect New Emotion"):
                st.session_state.page = "üì∏ Emotion Detection"
                st.rerun()
    else:
        st.warning("No recommendations available for this emotion. Showing Neutral playlist as fallback.")
        fallback = st.session_state.music_recommender.get_recommendations('neutral', 8)
        if fallback:
            # Display fallback directly without rerun to avoid loop
            st.markdown("### üéº Playlist Information (Neutral Fallback)")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Mood", fallback['mood'])
                st.metric("Tempo", fallback['tempo'])
            with col2:
                st.metric("Energy Level", fallback['energy'])
                st.metric("Valence", fallback['valence'])
            with col3:
                st.metric("Playlist Name", fallback['playlist_name'])
            st.markdown("### üéµ Recommended Songs")
            for i, song in enumerate(fallback['recommended_songs'], 1):
                st.markdown(f"""
                <div class="music-card">
                    <strong>{i}. {song}</strong>
                </div>
                """, unsafe_allow_html=True)

def show_analytics_page():
    """Display the analytics page"""
    st.markdown("## üìä Analytics & Insights")
    
    if st.session_state.last_prediction is None:
        st.warning("No emotion detection data available. Please detect an emotion first.")
        return
    
    emotion = st.session_state.last_prediction['emotion']
    all_predictions = st.session_state.last_prediction['all_predictions']
    
    # Minimal analysis: one concise chart
    st.markdown("### üìà Emotion Confidence Distribution")
    
    emotions = list(all_predictions.keys())
    values = list(all_predictions.values())
    
    fig = px.bar(
        x=emotions,
        y=values,
        title="Confidence Scores for All Emotions",
        labels={'x': 'Emotion', 'y': 'Confidence Score'},
        color=values,
        color_continuous_scale='Viridis'
    )
    
    fig.update_layout(
        xaxis_title="Emotion",
        yaxis_title="Confidence Score",
        showlegend=False
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Compact insights
    st.markdown("### üîç Quick Insights")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("#### Top Emotions")
        sorted_emotions = sorted(all_predictions.items(), key=lambda x: x[1], reverse=True)
        for i, (emotion_name, conf) in enumerate(sorted_emotions[:3], 1):
            emoji = st.session_state.music_recommender.get_emotion_emoji(emotion_name)
            st.write(f"{i}. {emoji} {emotion_name.title()}: {conf:.1%}")
    with col2:
        avg_confidence = sum(all_predictions.values()) / len(all_predictions)
        st.metric("Average Confidence", f"{avg_confidence:.1%}")

def show_about_page():
    """Display the about page"""
    st.markdown("## ‚ÑπÔ∏è About Emotion-Based Music Recommender")
    
    st.markdown("""
    ### üéØ Project Overview
    
    This application combines **Computer Vision**, **Deep Learning**, and **Music Psychology** to create a personalized music recommendation system based on facial emotion detection.
    
    ### üõ†Ô∏è Technical Stack
    
    - **Frontend**: Streamlit
    - **Deep Learning**: TensorFlow/Keras
    - **Computer Vision**: OpenCV
    - **Data Visualization**: Plotly
    - **Image Processing**: PIL (Pillow)
    
    ### üß† Model Architecture
    
    The emotion detection model uses a **Convolutional Neural Network (CNN)** with the following architecture:
    
    - **Input Layer**: 48x48 grayscale images
    - **Convolutional Layers**: 4 blocks with Batch Normalization and Dropout
    - **Dense Layers**: 512 and 256 neurons with regularization
    - **Output Layer**: 7 neurons (one for each emotion)
    - **Activation**: ReLU for hidden layers, Softmax for output
    
    ### üìä Dataset Information
    
    The model is trained on a dataset containing **28,709 images** across 7 emotion categories:
    
    - **Happy**: 7,215 images
    - **Neutral**: 4,965 images  
    - **Sad**: 4,830 images
    - **Angry**: 3,995 images
    - **Fear**: 4,097 images
    - **Surprise**: 3,171 images
    - **Disgust**: 436 images
    
    ### üéµ Music Recommendation System
    
    The music recommendation system uses a curated database with:
    
    - **50+ songs per emotion category**
    - **Multiple genres** for each emotion
    - **Mood-based filtering**
    - **Tempo and energy analysis**
    - **Artist recommendations**
    
    ### üöÄ Features
    
    - **Real-time emotion detection**
    - **Interactive visualizations**
    - **Personalized music recommendations**
    - **Comprehensive analytics**
    - **User-friendly interface**
    - **Mobile-responsive design**
    
    ### üìà Performance Metrics
    
    - **Accuracy**: 95%+ on test dataset
    - **Processing Time**: < 2 seconds per image
    - **Model Size**: ~50MB
    - **Supported Formats**: JPG, JPEG, PNG
    
    ### üîÆ Future Enhancements
    
    - **Real-time video emotion detection**
    - **Integration with music streaming services**
    - **User preference learning**
    - **Social sharing features**
    - **Mobile app development**
    
    ### üë®‚Äçüíª Development Team
    
    This project was developed as part of an AI/ML initiative to explore the intersection of computer vision and music recommendation systems.
    
    ### üìÑ License
    
    This project is open source and available under the MIT License.
    """)
    
    # Contact information
    st.markdown("---")
    st.markdown("### üìû Contact & Support")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**Email**")
        st.markdown("[py6632388@gmail.com](mailto:py6632388@gmail.com)")
    
    with col2:
        st.markdown("**GitHub**")
        st.markdown("[github.com/parmar-yash-04](https://github.com/parmar-yash-04)")
    
    with col3:
        st.markdown("**LinkedIn**")
        st.markdown("[linkedin.com/in/yash-parmar-yash04](https://www.linkedin.com/in/yash-parmar-yash04/)")

if __name__ == "__main__":
    main()
